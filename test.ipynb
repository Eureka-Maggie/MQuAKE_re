{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanhexiang/anaconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTJForCausalLM(\n",
       "  (transformer): GPTJModel(\n",
       "    (wte): Embedding(50400, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-27): 28 x GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=50400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "\n",
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/tanhexiang/gptj\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/home/tanhexiang/gptj\",torch_dtype=torch.float16).to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompts/MeLLo-prompt.txt', 'r') as f:\n",
    "    task_prompt = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generated_text_1 \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(output[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m index \u001b[39m=\u001b[39m generated_text_1\u001b[39m.\u001b[39mfind(Question)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(index)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "generated_text_1 = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "index = generated_text_1.find(Question)\n",
    "print(index)\n",
    "length = len(Question)\n",
    "rest = generated_text_1[index+length:]\n",
    "rf_index = rest.find('Retrieved fact:')\n",
    "generate_q_a = rest[:rf_index]\n",
    "print(\":\",generate_q_a,\":\")\n",
    "#print(task_prompt+generate_q_a)#这后面有个换行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(cur_prompt, start):\n",
    "    # 将输入文本编码为模型输入\n",
    "    input_ids = tokenizer.encode(cur_prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=input_ids.size()[1]+100,num_return_sequences=1)\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    rest = generated_text[start:]\n",
    "    fa_index = rest.find('\\n\\nQuestion:')#找final_ans\n",
    "    rf_index = rest.find('Retrieved fact:')\n",
    "    \n",
    "    if (fa_index > rf_index and rf_index!=-1 ) or fa_index == -1:\n",
    "        index = rf_index\n",
    "    else:\n",
    "        index = fa_index\n",
    "\n",
    "    generate_q_a = rest[:index]\n",
    "    #print(generate_q_a)\n",
    "    return generate_q_a\n",
    "#==============================for contriever====================================\n",
    "def mean_pooling(token_embeddings, mask):\n",
    "    token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "    sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "    return sentence_embeddings\n",
    "\n",
    "def get_sent_embeddings(sents, contriever, tok, BSZ=32):    \n",
    "    all_embs = []\n",
    "    for i in tqdm(range(0, len(sents), BSZ)):\n",
    "        sent_batch = sents[i:i+BSZ]\n",
    "        inputs = tok(sent_batch, padding=True, truncation=True, return_tensors='pt').to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            outputs = contriever(**inputs)\n",
    "            embeddings = mean_pooling(outputs[0], inputs['attention_mask'])\n",
    "        all_embs.append(embeddings)\n",
    "    all_embs = torch.vstack(all_embs)\n",
    "    return all_embs\n",
    "\n",
    "def retrieve_facts(query, fact_embs, contriever, tok, k=1):\n",
    "    inputs = tok([query], padding=True, truncation=True, return_tensors='pt').to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = contriever(**inputs)\n",
    "        query_emb = mean_pooling(outputs[0], inputs['attention_mask'])\n",
    "    sim = (query_emb @ fact_embs.T)[0]\n",
    "    knn = sim.topk(k, largest=True)\n",
    "    return knn.indices\n",
    "\n",
    "contriever = AutoModel.from_pretrained(\"/home/tanhexiang/contriever\").cuda()\n",
    "tokenizer_con = AutoTokenizer.from_pretrained(\"/home/tanhexiang/contriever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:02<00:00, 36.53it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/MQuAKE-CF-3k.json', 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "new_facts = set()\n",
    "for d in dataset:\n",
    "    for r in d[\"requested_rewrite\"]:\n",
    "        new_facts.add(f'{r[\"prompt\"].format(r[\"subject\"])} {r[\"target_new\"][\"str\"]}')\n",
    "new_facts = list(new_facts)\n",
    "\n",
    "embs = get_sent_embeddings(new_facts, contriever, tokenizer_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanhexiang/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "  2%|▏         | 56/3000 [52:58<46:25:16, 56.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):\n\u001b[1;32m     33\u001b[0m     \u001b[39m# prompt the model to generate a subquestion and a tentative answer\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     start \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(prompt)\n\u001b[0;32m---> 35\u001b[0m     gen \u001b[39m=\u001b[39m call_gpt(prompt, start)\n\u001b[1;32m     36\u001b[0m     gen_q\u001b[39m.\u001b[39mappend(gen)\n\u001b[1;32m     37\u001b[0m     last_sent \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mcall_gpt\u001b[0;34m(cur_prompt, start)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_gpt\u001b[39m(cur_prompt, start):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# 将输入文本编码为模型输入\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     input_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(cur_prompt, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 4\u001b[0m     output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(input_ids, max_length\u001b[39m=\u001b[39;49minput_ids\u001b[39m.\u001b[39;49msize()[\u001b[39m1\u001b[39;49m]\u001b[39m+\u001b[39;49m\u001b[39m100\u001b[39;49m,num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m     generated_text \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(output[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     rest \u001b[39m=\u001b[39m generated_text[start:]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/generation/utils.py:1602\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1585\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massisted_decoding(\n\u001b[1;32m   1586\u001b[0m         input_ids,\n\u001b[1;32m   1587\u001b[0m         assistant_model\u001b[39m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1599\u001b[0m     )\n\u001b[1;32m   1600\u001b[0m \u001b[39mif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1601\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1602\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1603\u001b[0m         input_ids,\n\u001b[1;32m   1604\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1605\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1606\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1607\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1608\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1609\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1610\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1611\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1612\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1613\u001b[0m     )\n\u001b[1;32m   1615\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1616\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/generation/utils.py:2450\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2447\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2449\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2450\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2451\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2452\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2453\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2454\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2455\u001b[0m )\n\u001b[1;32m   2457\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2458\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:855\u001b[0m, in \u001b[0;36mGPTJForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    853\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m--> 855\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m    856\u001b[0m     input_ids,\n\u001b[1;32m    857\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    858\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    859\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m    860\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    861\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    862\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    863\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    864\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    865\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    866\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    867\u001b[0m )\n\u001b[1;32m    868\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    870\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:690\u001b[0m, in \u001b[0;36mGPTJModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    681\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    682\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    683\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m         head_mask[i],\n\u001b[1;32m    688\u001b[0m     )\n\u001b[1;32m    689\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[1;32m    691\u001b[0m         hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    692\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    693\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    694\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    695\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m    696\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    697\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    698\u001b[0m     )\n\u001b[1;32m    700\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    701\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:309\u001b[0m, in \u001b[0;36mGPTJBlock.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, position_ids, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    307\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    308\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 309\u001b[0m attn_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[1;32m    310\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    311\u001b[0m     layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    312\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    313\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    314\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    315\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    316\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    318\u001b[0m attn_output \u001b[39m=\u001b[39m attn_outputs[\u001b[39m0\u001b[39m]  \u001b[39m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m outputs \u001b[39m=\u001b[39m attn_outputs[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:234\u001b[0m, in \u001b[0;36mGPTJAttention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, position_ids, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    231\u001b[0m q_pass \u001b[39m=\u001b[39m query[:, :, :, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrotary_dim :]\n\u001b[1;32m    233\u001b[0m k_rot \u001b[39m=\u001b[39m apply_rotary_pos_emb(k_rot, sin, cos)\n\u001b[0;32m--> 234\u001b[0m q_rot \u001b[39m=\u001b[39m apply_rotary_pos_emb(q_rot, sin, cos)\n\u001b[1;32m    236\u001b[0m key \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([k_rot, k_pass], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    237\u001b[0m query \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([q_rot, q_pass], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:78\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(tensor, sin, cos)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_rotary_pos_emb\u001b[39m(tensor: torch\u001b[39m.\u001b[39mTensor, sin: torch\u001b[39m.\u001b[39mTensor, cos: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     77\u001b[0m     sin \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrepeat_interleave(sin[:, :, \u001b[39mNone\u001b[39;00m, :], \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m     cos \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrepeat_interleave(cos[:, :, \u001b[39mNone\u001b[39;49;00m, :], \u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m)\n\u001b[1;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m (tensor \u001b[39m*\u001b[39m cos) \u001b[39m+\u001b[39m (rotate_every_two(tensor) \u001b[39m*\u001b[39m sin)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "T = 10\n",
    "\n",
    "cor = 0\n",
    "tot = 0\n",
    "start = len(task_prompt)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "record_list = []\n",
    "cor_list = []\n",
    "for d in tqdm(dataset):\n",
    "    #print(d)\n",
    "    real_edit = []\n",
    "    tot += 1\n",
    "    hop = len(d[\"new_single_hops\"])\n",
    "    real_hop = []\n",
    "    #print(hop)\n",
    "    #用于记录该问题应该retrieve哪些edit fact\n",
    "    for r in d[\"requested_rewrite\"]:\n",
    "        real_edit.append(f'{r[\"prompt\"].format(r[\"subject\"])} {r[\"target_new\"][\"str\"]}')\n",
    "    for h in d['new_single_hops']:\n",
    "        real_hop.append(h['question'])\n",
    "    cnt = 0\n",
    "    for q in d[\"questions\"]:\n",
    "        cnt+=1\n",
    "        retrieved_facts = []\n",
    "        found_ans = False\n",
    "        prompt = task_prompt + \"\\n\\nQustion: \" + q\n",
    "        flag = 0\n",
    "        gen_q = []\n",
    "        i = 0\n",
    "        for i in range(4):\n",
    "            # prompt the model to generate a subquestion and a tentative answer\n",
    "            start = len(prompt)\n",
    "            gen = call_gpt(prompt, start)\n",
    "            gen_q.append(gen)\n",
    "            last_sent = gen.strip().split('\\n')[-1]\n",
    "            \n",
    "            # if final answer is there, get the answer and exit\n",
    "            if last_sent.startswith('Final answer: '):\n",
    "                found_ans = True\n",
    "                ans = last_sent[len(\"Final answer: \"):]\n",
    "                break\n",
    "            \n",
    "            # otherwise, extract the generated subquestion\n",
    "            if len(gen.strip().split('\\n')) < 2:\n",
    "                record = {'id':tot,'hop':hop,'question':q,'real_edit':real_edit,'retrieve_facts':retrieved_facts,'real_hop:':real_hop,'gen_q':gen_q,'answer':\"failed_1\"}\n",
    "                record_list.append(record)\n",
    "                flag = 1\n",
    "                break # failed case\n",
    "            subquestion = gen.strip().split('\\n')[-2]\n",
    "            if not subquestion.startswith('Subquestion: '):#生成有问题\n",
    "                record = {'id':tot,'hop':hop,'question':q,'real_edit':real_edit,'retrieve_facts':retrieved_facts,'real_hop:':real_hop,'gen_q':gen_q,'answer':\"failed_2\"}\n",
    "                record_list.append(record)\n",
    "                flag = 1\n",
    "                break # failed case\n",
    "            subquestion = subquestion[len(\"Subquestion: \"):]\n",
    "            \n",
    "            # retrieve an edited fact using the generated subquestion\n",
    "            fact_ids = retrieve_facts(subquestion, embs, contriever, tokenizer_con)\n",
    "            fact_sent = new_facts[fact_ids[0]]\n",
    "            retrieved_facts.append(fact_sent)\n",
    "            \n",
    "            # put the retrieved fact at the end of the prompt, the model self-checks if it contradicts\n",
    "            prompt = prompt + gen + 'Retrieved fact: ' + fact_sent + '.'\n",
    "            \n",
    "        prompt = prompt + gen\n",
    "        \n",
    "        if not found_ans:\n",
    "            if flag == 0:\n",
    "                record = {'id':tot,'hop':hop,'question':q,'real_edit':real_edit,'retrieve_facts':retrieved_facts,'real_hop:':real_hop,'gen_q':gen_q,'answer':\"no_final_ans\"}\n",
    "                record_list.append(record)\n",
    "            continue\n",
    "        # if the answer is correct\n",
    "        if ans == d[\"new_answer\"] or ans in d[\"new_answer_alias\"]:\n",
    "            cor += 1\n",
    "            cor_record = {'id':tot,'hop':hop,'used_hop':i,'question':q,'real_edit':real_edit,'retrieve_facts':retrieved_facts,'real_hop:':real_hop,'gen_q':gen_q}\n",
    "            cor_list.append(cor_record)\n",
    "            break\n",
    "        else:\n",
    "            record = {'id':tot,'hop':hop,'question':q,'real_edit':real_edit,'retrieve_facts':retrieved_facts,'real_hop:':real_hop,'gen_q':gen_q,'answer':\"not_correct_ans\"}\n",
    "            record_list.append(record)\n",
    "            \n",
    "print(f'Multi-hop acc = {cor / tot} ({cor} / {tot})')\n",
    "\n",
    "import numpy as np\n",
    "np.savez('cor_list_3000_4',cor_list)\n",
    "np.savez('record_list_3000_4',record_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 2989,\n",
       " 'hop': 4,\n",
       " 'used_hop': 3,\n",
       " 'question': 'What is the name of the capital city of the country where the author of \"Rights of Man\" was from?',\n",
       " 'real_edit': ['The author of Rights of Man is Veronica Roth',\n",
       "  'Divergent was created in the country of United Kingdom',\n",
       "  'The capital of United Kingdom is Angri'],\n",
       " 'retrieve_facts': ['The author of Rights of Man is Veronica Roth',\n",
       "  'The capital of United Kingdom is Angri',\n",
       "  'The capital of United Kingdom is Angri'],\n",
       " 'real_hop:': ['Who is the author of Rights of Man?',\n",
       "  'What is Veronica Roth famous for?',\n",
       "  'Which country was Divergent created in?',\n",
       "  'What is the capital of United Kingdom?'],\n",
       " 'gen_q': ['\\nSubquestion: What is the name of the country where the author of \"Rights of Man\" was from?\\nGenerated answer: The author of \"Rights of Man\" was from United Kingdom.\\n',\n",
       "  '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United Kingdom\\nSubquestion: What is the name of the capital city of United Kingdom?\\nGenerated answer: The capital city of United Kingdom is London.\\n',\n",
       "  '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Angri\\nSubquestion: What is the name of the country where Angri is situated?\\nGenerated answer: The country where Angri is situated is United Kingdom.\\n',\n",
       "  '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Angri\\nFinal answer: Angri']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 : {'id': 6, 'hop': 4, 'used_hop': 4, 'question': \"In which city is the headquarters of the manufacturer of Ford Transit's founding company located?\", 'real_edit': ['The company that produced Ford Transit is Lotus Cars', 'Lotus Cars was founded by William Ruto', 'William Ruto is a citizen of South Korea', 'The capital of South Korea is Pasco'], 'retrieve_facts': ['The company that produced Ford Transit is Lotus Cars', 'Lotus Cars was founded by William Ruto', 'William Ruto is a citizen of South Korea', 'The capital of South Korea is Pasco'], 'real_hop:': ['Which company is Ford Transit produced by?', 'Who founded Lotus Cars?', 'What is the country of citizenship of William Ruto?', 'What is the capital of South Korea?'], 'gen_q': [\"\\nSubquestion: In which city is the headquarters of Ford Transit's founding company located?\\nGenerated answer: The headquarters of Ford Transit's founding company is in the city of Detroit.\\n\", '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Lotus Cars\\nSubquestion: In which city is Lotus Cars located?\\nGenerated answer: Lotus Cars is located in the city of Coventry.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Coventry\\nSubquestion: In which city is William Ruto located?\\nGenerated answer: William Ruto is located in the city of Nairobi.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: South Korea\\nSubquestion: In which city is South Korea situated?\\nGenerated answer: South Korea is situated in the continent of Asia.\\n', '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: Pasco\\nFinal answer: Pasco']}\n",
      "44 : {'id': 44, 'hop': 4, 'used_hop': 4, 'question': 'On which continent is the country of citizenship of the spouse of the author of \"Hard Times\" located?', 'real_edit': ['The author of Hard Times is Jonathan Swift', 'Jonathan Swift is married to Raghuvaran'], 'retrieve_facts': ['The author of Hard Times is Jonathan Swift', 'Jonathan Swift is married to Raghuvaran', 'Raghuvaran is a citizen of Israel', 'Israel is located in the continent of Australia'], 'real_hop:': ['Who is the author of Hard Times?', 'Who is Jonathan Swift married to?', 'What is the country of citizenship of Raghuvaran?', 'Which continent is India located in?'], 'gen_q': ['\\nSubquestion: Who is the author of \"Hard Times\"?\\nGenerated answer: The author of \"Hard Times\" is Charles Dickens.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Jonathan Swift\\nSubquestion: Who is the spouse of Jonathan Swift?\\nGenerated answer: The spouse of Jonathan Swift is Esther Johnson.\\n', '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: Raghuvaran\\nSubquestion: On which continent is Raghuvaran located?\\nGenerated answer: Raghuvaran is located on Asia.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Asia\\nSubquestion: On which continent is Israel situated?\\nGenerated answer: Israel is situated on Asia.\\n', '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: Asia\\nFinal answer: Asia']}\n",
      "65 : {'id': 65, 'hop': 4, 'used_hop': 4, 'question': \"The manufacturer of Me 262 holds citizenship in which continent's country?\", 'real_edit': ['The company that produced Me 262 is Toyota', 'Toyota was founded by Anwar Ibrahim', 'Anwar Ibrahim is a citizen of Serbia', 'Serbia is located in the continent of Asia'], 'retrieve_facts': ['The company that produced Me 262 is Toyota', 'The chief executive officer of Toyota is Marc Benioff', 'Hikaru Sato is a citizen of United States of America', 'Japan is located in the continent of Oceania'], 'real_hop:': ['Which company is Me 262 produced by?', 'Who founded Toyota?', 'What is the country of citizenship of Anwar Ibrahim?', 'Which continent is Serbia located in?'], 'gen_q': [\"\\nSubquestion: Which continent's country is the manufacturer of Me 262 situated?\\nGenerated answer: The manufacturer of Me 262 is Daimler AG.\\n\", '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Toyota\\nSubquestion: Who is the founder of Toyota?\\nGenerated answer: Toyota was founded by Kiichiro Toyoda.\\n', '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: Kiichiro Toyoda\\nSubquestion: What is the country of citizenship of Kiichiro Toyoda?\\nGenerated answer: Kiichiro Toyoda is a citizen of Japan.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Japan\\nSubquestion: On which continent is Japan situated?\\nGenerated answer: Japan is situated on Asia.\\n', '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: Asia\\nFinal answer: Asia']}\n",
      "76 : {'id': 76, 'hop': 4, 'used_hop': 4, 'question': 'What is the name of the continent where the CEO of the developer of Xbox Live Indie Games was born?', 'real_edit': ['Xbox Live Indie Games was developed by Sony Interactive Entertainment', 'The chief executive officer of Sony Interactive Entertainment is Marc Benioff', 'Marc Benioff was born in the city of California', 'California is located in the continent of Europe'], 'retrieve_facts': ['Xbox Live Indie Games was developed by Sony Interactive Entertainment', 'The chief executive officer of Sony Interactive Entertainment is Marc Benioff', 'Marc Benioff is a citizen of Scotland', 'Scotland is located in the continent of North America'], 'real_hop:': ['Who is the developer of Xbox Live Indie Games?', 'Who is the chief executive officer of Sony Interactive Entertainment?', 'Which city was Marc Benioff born in?', 'Which continent is California located in?'], 'gen_q': ['\\nSubquestion: What is the name of the developer of Xbox Live Indie Games?\\nGenerated answer: The developer of Xbox Live Indie Games is Microsoft.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Sony Interactive Entertainment\\nSubquestion: What is the name of the CEO of Sony Interactive Entertainment?\\nGenerated answer: The CEO of Sony Interactive Entertainment is John Kodera.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: John Kodera\\nSubquestion: What is the name of the continent where Marc Benioff was born?\\nGenerated answer: Marc Benioff was born in the continent of Europe.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Europe\\nSubquestion: What is the name of the continent where Scotland is situated?\\nGenerated answer: Scotland is situated in the continent of Europe.\\n', '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: Europe\\nFinal answer: Europe']}\n",
      "77 : {'id': 77, 'hop': 4, 'used_hop': 4, 'question': \"What is the capital city of the country from which Tony Parker's sport originates?\", 'real_edit': ['Tony Parker plays the position of defenceman', 'defenceman is associated with the sport of Muay Thai', 'Muay Thai was created in the country of Australia', 'The capital of Australia is Kütahya'], 'retrieve_facts': ['Tony Parker plays the position of defenceman', 'defenceman is associated with the sport of Muay Thai', 'Muay Thai was created in the country of Australia', 'The capital of Australia is Kütahya'], 'real_hop:': ['What position does Tony Parker play?', 'Which sport is defenceman associated with?', 'Which country was Muay Thai created in?', 'What is the capital of Australia?'], 'gen_q': ['\\nSubquestion: What is the sport of Tony Parker?\\nGenerated answer: Tony Parker is a basketball player.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: defenceman\\nSubquestion: What is the sport of defenceman?\\nGenerated answer: The sport of defenceman is ice hockey.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Muay Thai\\nSubquestion: What is the country of citizenship of Muay Thai?\\nGenerated answer: Muay Thai is a sport of Thailand.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Australia\\nSubquestion: What is the capital city of Australia?\\nGenerated answer: The capital city of Australia is Canberra.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Kütahya\\nFinal answer: Kütahya']}\n",
      "95 : {'id': 95, 'hop': 4, 'used_hop': 4, 'question': 'Which city serves as the capital of the country where the founder of Ford Sync holds its nationality?', 'real_edit': ['Ford Sync was developed by Bell Labs', 'Bell Labs was founded by Pierre Karl Péladeau'], 'retrieve_facts': ['Ford Sync was developed by Bell Labs', 'Bell Labs was founded by Pierre Karl Péladeau', 'Bell Labs was founded by Pierre Karl Péladeau', 'The capital of Canada is Bueng Kan'], 'real_hop:': ['Who is the developer of Ford Sync?', 'Who founded Bell Labs?', 'What is the country of citizenship of Pierre Karl Péladeau?', 'What is the capital of Canada?'], 'gen_q': ['\\nSubquestion: Which company is Ford Sync produced by?\\nGenerated answer: Ford Sync is produced by Ford.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Bell Labs\\nSubquestion: Who is the founder of Bell Labs?\\nGenerated answer: Bell Labs was founded by Alexander Graham Bell.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Pierre Karl Péladeau\\nSubquestion: What is the country of citizenship of Pierre Karl Péladeau?\\nGenerated answer: Pierre Karl Péladeau is a citizen of Canada.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Canada\\nSubquestion: What is the capital city of Canada?\\nGenerated answer: The capital city of Canada is Ottawa.\\n', '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Ottawa\\nFinal answer: Ottawa']}\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for r in cor_list:\n",
    "    if r['used_hop']==r['hop']:\n",
    "        cnt+=1\n",
    "        print(r['id'],\":\",r)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez('cor_list_3000',cor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.084"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_list\n",
    "with open(\"record_list_h100.json\", \"w\") as f:\n",
    "    json.dump(record_list, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'hop': 2,\n",
       "  'question': 'Who is the head of state of the country where Ellie Kemper holds a citizenship?',\n",
       "  'real_edit': ['Ellie Kemper is a citizen of Croatia'],\n",
       "  'retrieve_facts': ['Ellie Kemper is a citizen of Croatia',\n",
       "   'The name of the current head of state in Austria is Kingdom of Italy',\n",
       "   'The name of the current head of state in Italy is Mamnoon Hussain',\n",
       "   'The name of the current head of state in Italy is Mamnoon Hussain'],\n",
       "  'real_hop:': ['What is the country of citizenship of Ellie Kemper?',\n",
       "   'What is the name of the current head of state in Croatia?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the current head of state in the country where Ellie Kemper holds a citizenship?\\nGenerated answer: The head of state of the country where Ellie Kemper holds a citizenship is President Barack Obama.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Croatia\\nSubquestion: What is the name of the current head of state in Croatia?\\nGenerated answer: The head of state of Croatia is Kolinda Grabar-Kitarović.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Kolinda Grabar-Kitarović\\nSubquestion: What is the name of the current head of state in Italy?\\nGenerated answer: The head of state of Italy is Sergio Mattarella.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Mamnoon Hussain\\nSubquestion: What is the name of the current head of state in the Kingdom of Italy?\\nGenerated answer: The head of state of the Kingdom of Italy is Sergio Mattarella.\\n'],\n",
       "  'answer': 'no_final_ans'},\n",
       " {'id': 2,\n",
       "  'hop': 2,\n",
       "  'question': 'Which writer\\'s country of citizenship is the same as the author of \"Misery\"?',\n",
       "  'real_edit': ['The author of Misery is Richard Dawkins'],\n",
       "  'retrieve_facts': ['The author of Misery is Richard Dawkins',\n",
       "   'Richard Dawkins is married to Jacques Chirac'],\n",
       "  'real_hop:': ['Who is the author of Misery?',\n",
       "   'What is the country of citizenship of Richard Dawkins?'],\n",
       "  'gen_q': ['\\nSubquestion: Which writer is Misery written by?\\nGenerated answer: Misery is written by Stephen King.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Richard Dawkins\\nSubquestion: What is the country of citizenship of Richard Dawkins?\\nGenerated answer: Richard Dawkins is a citizen of United Kingdom.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United Kingdom\\nSubquestion: What is the capital city of United Kingdom?\\nGenerated answer: The capital city of United Kingdom is London.\\nRetrieved fact: The capital city of United Kingdom is Edinburgh.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Edinburgh\\nFinal answer: Edinburgh'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 2,\n",
       "  'hop': 2,\n",
       "  'question': 'What country does the author of \"Misery\" and another writer share their citizenship?',\n",
       "  'real_edit': ['The author of Misery is Richard Dawkins'],\n",
       "  'retrieve_facts': ['The author of The Sandman is F. Scott Fitzgerald',\n",
       "   'F. Scott Fitzgerald is a citizen of Italy'],\n",
       "  'real_hop:': ['Who is the author of Misery?',\n",
       "   'What is the country of citizenship of Richard Dawkins?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the other writer?\\nGenerated answer: The other writer is John Grisham.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: John Grisham\\nSubquestion: What is the name of the country of citizenship of F. Scott Fitzgerald?\\nGenerated answer: The country of citizenship of F. Scott Fitzgerald is United States of America.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Italy\\nSubquestion: What is the capital city of Italy?\\nGenerated answer: The capital city of Italy is Rome.\\nRetrieved fact: The capital city of United States of America is Washington, D.C.\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: Rome\\nFinal answer: Rome'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 2,\n",
       "  'hop': 2,\n",
       "  'question': 'What is the nationality of the author of \"Misery\"?',\n",
       "  'real_edit': ['The author of Misery is Richard Dawkins'],\n",
       "  'retrieve_facts': ['The author of Misery is Richard Dawkins',\n",
       "   'Richard Dawkins is married to Jacques Chirac'],\n",
       "  'real_hop:': ['Who is the author of Misery?',\n",
       "   'What is the country of citizenship of Richard Dawkins?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the author of \"Misery\"?\\nGenerated answer: The author of \"Misery\" is Stephen King.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Richard Dawkins\\nSubquestion: What is the name of the country of citizenship of Richard Dawkins?\\nGenerated answer: The country of citizenship of Richard Dawkins is United Kingdom.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United Kingdom\\nSubquestion: What is the name of the capital city of United Kingdom?\\nGenerated answer: The capital city of United Kingdom is London.\\nRetrieved fact: The capital city of United Kingdom is Edinburgh.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: London\\nFinal answer: London'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 3,\n",
       "  'hop': 2,\n",
       "  'question': 'What is the capital city of the country that Michael Feinstein is a citizen of?',\n",
       "  'real_edit': ['The capital of United States of America is El Campu'],\n",
       "  'retrieve_facts': ['Joe Biden is a citizen of Vietnam',\n",
       "   'The capital of Turkey is Mendoza'],\n",
       "  'real_hop:': ['What is the country of citizenship of Michael Feinstein?',\n",
       "   'What is the capital of United States of America?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the country that Michael Feinstein is a citizen of?\\nGenerated answer: The country that Michael Feinstein is a citizen of is United States of America.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Vietnam\\nSubquestion: What is the capital city of Vietnam?\\nGenerated answer: The capital city of Vietnam is Hanoi.\\n',\n",
       "   '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: Mendoza\\nSubquestion: What is the name of the country that Mendoza is the capital of?\\nGenerated answer: The country that Mendoza is the capital of is Argentina.\\nRetrieved fact: The capital of Argentina is Buenos Aires.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Mendoza\\nFinal answer: Mendoza'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 3,\n",
       "  'hop': 2,\n",
       "  'question': 'Which city serves as the capital of the country to which Michael Feinstein belongs?',\n",
       "  'real_edit': ['The capital of United States of America is El Campu'],\n",
       "  'retrieve_facts': ['Michael Corleone was created by Terry Nation',\n",
       "   'Michael Corleone was created by Terry Nation',\n",
       "   \"Terry Nation is famous for Arba'ah Turim\"],\n",
       "  'real_hop:': ['What is the country of citizenship of Michael Feinstein?',\n",
       "   'What is the capital of United States of America?'],\n",
       "  'gen_q': ['\\nSubquestion: Which city is the capital of the country to which Michael Feinstein belongs?\\nGenerated answer: The capital of the country to which Michael Feinstein belongs is New York.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: New York\\nSubquestion: Who is the creator of Michael Corleone?\\nGenerated answer: Michael Corleone was created by Terry Nation.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Terry Nation\\nSubquestion: What is the name of the country to which Terry Nation belongs?\\nGenerated answer: The country to which Terry Nation belongs is United States of America.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United States of America\\nSubquestion: What is the capital city of the country to which Terry Nation belongs?\\nGenerated answer: The capital city of the country to which Terry Nation belongs is Washington.\\nRetrieved fact: The capital city of the country to which Terry Nation belongs is Washington.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Washington\\nFinal answer: Washington'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 3,\n",
       "  'hop': 2,\n",
       "  'question': 'What is the name of the capital city of the country of which Michael Feinstein has citizenship?',\n",
       "  'real_edit': ['The capital of United States of America is El Campu'],\n",
       "  'retrieve_facts': ['Joe Biden is a citizen of Vietnam',\n",
       "   'The capital of Turkey is Mendoza',\n",
       "   'The capital of Turkey is Mendoza'],\n",
       "  'real_hop:': ['What is the country of citizenship of Michael Feinstein?',\n",
       "   'What is the capital of United States of America?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the capital city of the country of which Michael Feinstein has citizenship?\\nGenerated answer: The capital city of the country of which Michael Feinstein has citizenship is New York.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Vietnam\\nSubquestion: What is the name of the capital city of Vietnam?\\nGenerated answer: The capital city of Vietnam is Hanoi.\\n',\n",
       "   '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: Mendoza\\nSubquestion: What is the name of the capital city of Mendoza?\\nGenerated answer: The capital city of Mendoza is Mendoza.\\n',\n",
       "   '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: Mendoza\\nFinal answer: Mendoza'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 4,\n",
       "  'hop': 2,\n",
       "  'question': 'What is the capital of the country to which Lou Pearlman belonged?',\n",
       "  'real_edit': ['Lou Pearlman is a citizen of India',\n",
       "   'The capital of India is Taloga'],\n",
       "  'retrieve_facts': ['Lou Pearlman is a citizen of India',\n",
       "   'The capital of Spain is Bengaluru'],\n",
       "  'real_hop:': ['What is the country of citizenship of Lou Pearlman?',\n",
       "   'What is the capital of India?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the country to which Lou Pearlman belonged?\\nGenerated answer: The country to which Lou Pearlman belonged is United States of America.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: India\\nSubquestion: What is the capital of India?\\nGenerated answer: The capital of India is New Delhi.\\n',\n",
       "   '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: New Delhi\\nSubquestion: What is the name of the capital of Spain?\\nGenerated answer: The name of the capital of Spain is Madrid.\\nRetrieved fact: The capital of India is New Delhi.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: New Delhi\\nFinal answer: New Delhi'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 4,\n",
       "  'hop': 2,\n",
       "  'question': 'Which city serves as the capital of the country where Lou Pearlman was a citizen?',\n",
       "  'real_edit': ['Lou Pearlman is a citizen of India',\n",
       "   'The capital of India is Taloga'],\n",
       "  'retrieve_facts': ['Lou Pearlman is a citizen of India',\n",
       "   'The capital of Spain is Bengaluru'],\n",
       "  'real_hop:': ['What is the country of citizenship of Lou Pearlman?',\n",
       "   'What is the capital of India?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the country where Lou Pearlman was a citizen?\\nGenerated answer: The country where Lou Pearlman was a citizen is United States of America.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: India\\nSubquestion: What is the name of the capital city of India?\\nGenerated answer: The capital city of India is New Delhi.\\n',\n",
       "   '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: New Delhi\\nSubquestion: What is the name of the capital city of Spain?\\nGenerated answer: The capital city of Spain is Madrid.\\nRetrieved fact: The capital city of India is New Delhi.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: New Delhi\\nFinal answer: New Delhi'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 4,\n",
       "  'hop': 2,\n",
       "  'question': 'In which city is the capital of the country where Lou Pearlman had citizenship?',\n",
       "  'real_edit': ['Lou Pearlman is a citizen of India',\n",
       "   'The capital of India is Taloga'],\n",
       "  'retrieve_facts': ['Lou Pearlman is a citizen of India',\n",
       "   'The capital of Spain is Bengaluru'],\n",
       "  'real_hop:': ['What is the country of citizenship of Lou Pearlman?',\n",
       "   'What is the capital of India?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the country where Lou Pearlman had citizenship?\\nGenerated answer: The country where Lou Pearlman had citizenship is United States of America.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: India\\nSubquestion: What is the name of the capital of India?\\nGenerated answer: The capital of India is New Delhi.\\n',\n",
       "   '\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: New Delhi\\nSubquestion: What is the name of the capital of Spain?\\nGenerated answer: The capital of Spain is Madrid.\\nRetrieved fact: The capital of India is New Delhi.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: New Delhi\\nFinal answer: New Delhi'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 5,\n",
       "  'hop': 2,\n",
       "  'question': \"Which continent does Emma Bunton's country of citizenship belong to?\",\n",
       "  'real_edit': ['United Kingdom is located in the continent of Asia'],\n",
       "  'retrieve_facts': ['Selena Gomez is a citizen of England',\n",
       "   'Selena Gomez is a citizen of England',\n",
       "   'Selena Gomez is a citizen of England'],\n",
       "  'real_hop:': ['What is the country of citizenship of Emma Bunton?',\n",
       "   'Which continent is United Kingdom located in?'],\n",
       "  'gen_q': [\"\\nSubquestion: Which continent does Emma Bunton's country of citizenship belong to?\\nGenerated answer: Emma Bunton's country of citizenship is United Kingdom.\\n\",\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United Kingdom\\nSubquestion: What is the name of the country of citizenship of Selena Gomez?\\nGenerated answer: The name of the country of citizenship of Selena Gomez is United Kingdom.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United Kingdom\\nSubquestion: What is the capital city of the country of citizenship of Selena Gomez?\\nGenerated answer: The capital city of the country of citizenship of Selena Gomez is London.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: London\\nSubquestion: What is the name of the capital city of England?\\nGenerated answer: The name of the capital city of England is London.\\nRetrieved fact: The name of the capital city of United Kingdom is London.\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: London\\nFinal answer: London'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 5,\n",
       "  'hop': 2,\n",
       "  'question': 'To which continent does the country Emma Bunton holds citizenship pertain to?',\n",
       "  'real_edit': ['United Kingdom is located in the continent of Asia'],\n",
       "  'retrieve_facts': ['Selena Gomez is a citizen of England',\n",
       "   'Selena Gomez is a citizen of England',\n",
       "   'Selena Gomez is a citizen of England',\n",
       "   'Selena Gomez is a citizen of England'],\n",
       "  'real_hop:': ['What is the country of citizenship of Emma Bunton?',\n",
       "   'Which continent is United Kingdom located in?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the country of citizenship of Emma Bunton?\\nGenerated answer: Emma Bunton is a citizen of United Kingdom.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United Kingdom\\nSubquestion: What is the name of the country of citizenship of Selena Gomez?\\nGenerated answer: Selena Gomez is a citizen of United States of America.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United Kingdom\\nSubquestion: What is the name of the country of citizenship of Selena Gomez?\\nGenerated answer: Selena Gomez is a citizen of United States of America.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United Kingdom\\nSubquestion: What is the name of the country of citizenship of Selena Gomez?\\nGenerated answer: Selena Gomez is a citizen of United States of America.\\n'],\n",
       "  'answer': 'no_final_ans'},\n",
       " {'id': 5,\n",
       "  'hop': 2,\n",
       "  'question': 'In which continent is the country that Emma Bunton is a citizen of located?',\n",
       "  'real_edit': ['United Kingdom is located in the continent of Asia'],\n",
       "  'retrieve_facts': ['London is located in the continent of Australia',\n",
       "   'London is located in the continent of Australia',\n",
       "   'California is located in the continent of Europe',\n",
       "   'Italy is located in the continent of Asia'],\n",
       "  'real_hop:': ['What is the country of citizenship of Emma Bunton?',\n",
       "   'Which continent is United Kingdom located in?'],\n",
       "  'gen_q': ['\\nSubquestion: In which continent is the country that Emma Bunton is a citizen of located?\\nGenerated answer: Emma Bunton is a citizen of United Kingdom.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Australia\\nSubquestion: In which continent is London located?\\nGenerated answer: London is located in the continent of Europe.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Europe\\nSubquestion: In which continent is the continent of Europe located?\\nGenerated answer: The continent of Europe is located in the continent of Asia.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Asia\\nSubquestion: In which continent is the continent of Asia located?\\nGenerated answer: The continent of Asia is located in the continent of Africa.\\n'],\n",
       "  'answer': 'no_final_ans'},\n",
       " {'id': 6,\n",
       "  'hop': 2,\n",
       "  'question': 'Where was the creator of Tetris born?',\n",
       "  'real_edit': ['Tetris was created by Mark Burnett',\n",
       "   'Mark Burnett was born in the city of Manila'],\n",
       "  'retrieve_facts': ['Tetris was created by Mark Burnett',\n",
       "   'Tetris was created by Mark Burnett',\n",
       "   'Jay-Z was born in the city of Irkutsk'],\n",
       "  'real_hop:': ['Who was Tetris created by?',\n",
       "   'Which city was Mark Burnett born in?'],\n",
       "  'gen_q': ['\\nSubquestion: Where was the creator of Tetris born?\\nGenerated answer: Tetris was created by Alexey Pajitnov.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Mark Burnett\\nSubquestion: Who is the creator of Tetris?\\nGenerated answer: Tetris was created by Alexey Pajitnov.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Alexey Pajitnov\\nSubquestion: Where was Alexey Pajitnov born?\\nGenerated answer: Alexey Pajitnov was born in Russia.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Irkutsk\\nSubquestion: Where is Irkutsk situated?\\nGenerated answer: Irkutsk is situated in Russia.\\nRetrieved fact: Irkutsk is situated in Russia.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Russia\\nFinal answer: Russia'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 7,\n",
       "  'hop': 2,\n",
       "  'question': \"What country is the home to the Cincinnati Gardens' sport?\",\n",
       "  'real_edit': ['Cincinnati Gardens is associated with the sport of association football',\n",
       "   'association football was created in the country of Hong Kong'],\n",
       "  'retrieve_facts': ['Cincinnati Gardens is associated with the sport of association football',\n",
       "   'Zinedine Zidane is associated with the sport of cricket'],\n",
       "  'real_hop:': ['Which sport is Cincinnati Gardens associated with?',\n",
       "   'Which country was association football created in?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the sport played in Cincinnati Gardens?\\nGenerated answer: The sport played in Cincinnati Gardens is basketball.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: association football\\nSubquestion: What is the name of the sport played in association football?\\nGenerated answer: The sport played in association football is football.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: cricket\\nSubquestion: What is the name of the sport played in cricket?\\nGenerated answer: The sport played in cricket is cricket.\\nRetrieved fact: The sport played in cricket is cricket.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: cricket\\nFinal answer: cricket'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 7,\n",
       "  'hop': 2,\n",
       "  'question': 'In which country was the sport associated with Cincinnati Gardens first established?',\n",
       "  'real_edit': ['Cincinnati Gardens is associated with the sport of association football',\n",
       "   'association football was created in the country of Hong Kong'],\n",
       "  'retrieve_facts': ['Cincinnati Gardens is associated with the sport of association football',\n",
       "   'Zinedine Zidane is associated with the sport of cricket'],\n",
       "  'real_hop:': ['Which sport is Cincinnati Gardens associated with?',\n",
       "   'Which country was association football created in?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the sport associated with Cincinnati Gardens?\\nGenerated answer: The sport associated with Cincinnati Gardens is basketball.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: association football\\nSubquestion: What is the name of the sport of association football?\\nGenerated answer: The sport of association football is football.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: association football\\nSubquestion: What is the name of the sport of cricket?\\nGenerated answer: The sport of cricket is cricket.\\nRetrieved fact: The sport of cricket is cricket.\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: cricket\\nFinal answer: cricket'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 7,\n",
       "  'hop': 2,\n",
       "  'question': 'From which country did the sport of Cincinnati Gardens originate?',\n",
       "  'real_edit': ['Cincinnati Gardens is associated with the sport of association football',\n",
       "   'association football was created in the country of Hong Kong'],\n",
       "  'retrieve_facts': ['Cincinnati Gardens is associated with the sport of association football',\n",
       "   'Zinedine Zidane is associated with the sport of cricket'],\n",
       "  'real_hop:': ['Which sport is Cincinnati Gardens associated with?',\n",
       "   'Which country was association football created in?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the name of the sport of Cincinnati Gardens?\\nGenerated answer: Cincinnati Gardens is a sport of the United States of America.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Association football\\nSubquestion: What is the name of the sport of association football?\\nGenerated answer: The sport of association football is football.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Association football\\nSubquestion: What is the name of the sport of cricket?\\nGenerated answer: The sport of cricket is cricket.\\nRetrieved fact: The sport of cricket is cricket.\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: cricket\\nFinal answer: cricket'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 8,\n",
       "  'hop': 2,\n",
       "  'question': 'What is the official language of the country that William Gillette was a citizen of?',\n",
       "  'real_edit': ['William Gillette is a citizen of Indonesia',\n",
       "   'The official language of Indonesia is German'],\n",
       "  'retrieve_facts': ['William Gillette is a citizen of Indonesia',\n",
       "   'The official language of Indonesia is German',\n",
       "   'The official language of Germany is Spanish',\n",
       "   'The official language of Spain is Arabic'],\n",
       "  'real_hop:': ['What is the country of citizenship of William Gillette?',\n",
       "   'What is the official language of Indonesia?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the official language of the country that William Gillette was a citizen of?\\nGenerated answer: The official language of the country that William Gillette was a citizen of is English.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Indonesia\\nSubquestion: What is the official language of Indonesia?\\nGenerated answer: The official language of Indonesia is Indonesian.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Indonesian\\nSubquestion: What is the official language of Germany?\\nGenerated answer: The official language of Germany is German.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: German\\nSubquestion: What is the official language of Spain?\\nGenerated answer: The official language of Spain is Spanish.\\n'],\n",
       "  'answer': 'no_final_ans'},\n",
       " {'id': 8,\n",
       "  'hop': 2,\n",
       "  'question': \"Which language is the official language of William Gillette's country of citizenship?\",\n",
       "  'real_edit': ['William Gillette is a citizen of Indonesia',\n",
       "   'The official language of Indonesia is German'],\n",
       "  'retrieve_facts': ['William Gillette is a citizen of Indonesia',\n",
       "   'The official language of Indonesia is German'],\n",
       "  'real_hop:': ['What is the country of citizenship of William Gillette?',\n",
       "   'What is the official language of Indonesia?'],\n",
       "  'gen_q': ['\\nSubquestion: Which language is the official language of the country of citizenship of William Gillette?\\nGenerated answer: The official language of the country of citizenship of William Gillette is English.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: English\\nSubquestion: What is the official language of Indonesia?\\nGenerated answer: The official language of Indonesia is Bahasa Indonesia.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Bahasa Indonesia\\nSubquestion: What is the name of the official language of Indonesia?\\nGenerated answer: The official language of Indonesia is Bahasa Indonesia.\\nRetrieved fact: The official language of Indonesia is Bahasa Indonesia.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Bahasa Indonesia\\nFinal answer: Bahasa Indonesia'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 8,\n",
       "  'hop': 2,\n",
       "  'question': 'What is the language that is used officially in the country of citizenship of William Gillette?',\n",
       "  'real_edit': ['William Gillette is a citizen of Indonesia',\n",
       "   'The official language of Indonesia is German'],\n",
       "  'retrieve_facts': ['William Gillette is a citizen of Indonesia',\n",
       "   'The official language of Indonesia is German'],\n",
       "  'real_hop:': ['What is the country of citizenship of William Gillette?',\n",
       "   'What is the official language of Indonesia?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the language that is used officially in the country of citizenship of William Gillette?\\nGenerated answer: The language that is used officially in the country of citizenship of William Gillette is English.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: English\\nSubquestion: What is the official language of Indonesia?\\nGenerated answer: The official language of Indonesia is Bahasa Indonesia.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Bahasa Indonesia\\nSubquestion: What is the official language of Germany?\\nGenerated answer: The official language of Germany is German.\\nRetrieved fact: The official language of Germany is English.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: German\\nFinal answer: English'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 9,\n",
       "  'hop': 2,\n",
       "  'question': 'What is the birthplace of the spouse of William Howard Taft?',\n",
       "  'real_edit': ['William Howard Taft is married to Louis X of France',\n",
       "   'Louis X of France was born in the city of Denison'],\n",
       "  'retrieve_facts': ['William Howard Taft is married to Louis X of France',\n",
       "   'Louis XI of France is a citizen of United States of America'],\n",
       "  'real_hop:': ['Who is William Howard Taft married to?',\n",
       "   'Which city was Louis X of France born in?'],\n",
       "  'gen_q': ['\\nSubquestion: What is the birthplace of William Howard Taft?\\nGenerated answer: William Howard Taft was born in Ohio.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Louis X of France\\nSubquestion: What is the birthplace of Louis X of France?\\nGenerated answer: Louis X of France was born in France.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United States of America\\nSubquestion: What is the birthplace of United States of America?\\nGenerated answer: United States of America was born in United States.\\nRetrieved fact: United States of America was born in United States.\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United States\\nFinal answer: United States'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 9,\n",
       "  'hop': 2,\n",
       "  'question': 'Where did the partner of William Howard Taft come from?',\n",
       "  'real_edit': ['William Howard Taft is married to Louis X of France',\n",
       "   'Louis X of France was born in the city of Denison'],\n",
       "  'retrieve_facts': ['William Howard Taft is married to Louis X of France',\n",
       "   'William Howard Taft is married to Louis X of France',\n",
       "   'William Howard Taft is married to Louis X of France'],\n",
       "  'real_hop:': ['Who is William Howard Taft married to?',\n",
       "   'Which city was Louis X of France born in?'],\n",
       "  'gen_q': ['\\nSubquestion: Where is the country of citizenship of William Howard Taft?\\nGenerated answer: William Howard Taft is a citizen of United States of America.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Louis X of France\\nSubquestion: Who is the spouse of William Howard Taft?\\nGenerated answer: The spouse of William Howard Taft is Helen Taft.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Helen Taft\\nSubquestion: What is the country of citizenship of Helen Taft?\\nGenerated answer: Helen Taft is a citizen of United States of America.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: United States of America\\nSubquestion: What is the capital city of United States of America?\\nGenerated answer: The capital city of United States of America is Washington.\\nRetrieved fact: The capital city of United States of America is Washington.\\nRetrieved fact does not contradict to generated answer, so the intermediate answer is: Washington\\nFinal answer: Washington'],\n",
       "  'answer': 'not_correct_ans'},\n",
       " {'id': 9,\n",
       "  'hop': 2,\n",
       "  'question': 'In which city was the partner of William Howard Taft born?',\n",
       "  'real_edit': ['William Howard Taft is married to Louis X of France',\n",
       "   'Louis X of France was born in the city of Denison'],\n",
       "  'retrieve_facts': ['William Howard Taft is married to Louis X of France',\n",
       "   'William Howard Taft is married to Louis X of France',\n",
       "   'William Howard Taft is married to Louis X of France'],\n",
       "  'real_hop:': ['Who is William Howard Taft married to?',\n",
       "   'Which city was Louis X of France born in?'],\n",
       "  'gen_q': ['\\nSubquestion: In which city was the partner of William Howard Taft born?\\nGenerated answer: The partner of William Howard Taft was Helen Herron Taft.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Helen Herron Taft\\nSubquestion: In which city was Helen Herron Taft born?\\nGenerated answer: Helen Herron Taft was born in Cincinnati, Ohio.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Helen Herron Taft\\nSubquestion: In which city was Helen Herron Taft born?\\nGenerated answer: Helen Herron Taft was born in Cincinnati, Ohio.\\n',\n",
       "   '\\nRetrieved fact contradicts to generated answer, so the intermediate answer is: Helen Herron Taft\\nFinal answer: Helen Herron Taft'],\n",
       "  'answer': 'not_correct_ans'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单独问retrieve_fact和generated_ans看会不会判断错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated answer: Ivanka Trump's spouse is Jared Kushner.\n",
      "Retrieved fact: Ivanka Biden is married to Samantha Cameron.\n",
      "Retrieved fact does not contradict to generated answer, so the intermediate answer is: Jared Kushner\n",
      "\n",
      "Generated answer: The country of citizenship of Jared Kushner is United States.\n",
      "Retrieved fact: Jared Kushner is a citizen of Canada.\n",
      "Retrieved fact contradicts to generated answer, so the intermediate answer is: Canada\n",
      "\n",
      "Generated answer:  The capital city of Canada is Ottawa.\n",
      "Retrieved fact: The capital city of United States of America is Seattle.\n",
      "Retrieved fact does not contradict to generated answer, so the intermediate answer is: Ottawa\n",
      "\n",
      "Generated answer: Rainn Wilson is a citizen of United States of America.\n",
      "Retrieved fact: Rainn Wilson is a citizen of Croatia.\n",
      "Retrieved fact contradicts to generated answer, so the intermediate answer is: Croatia\n",
      "\n",
      "Generated answer: The head of state of Croatia is President Zoran Milanović.\n",
      "Retrieved fact: The name of the current head of state in Croatia is Kolinda Grabar-Kitarović.\n",
      "Retrieved fact contradicts to generated answer, so the intermediate answer is: Kolinda Grabar-Kitarović\n",
      "\n",
      "Generated answer: The US president is Donald Trump.\n",
      "Retrieved fact: The head of state in United States of America is Joe Biden.\n",
      "Retrieved fact contradicts to generated answer, so the intermediate answer is: Joe Biden\n",
      "\n",
      "Generated answer: The spouse of Joe Biden is Jill Biden.\n",
      "Retrieved fact: The spouse of Joe Bill is Evan Austin.\n",
      "Retrieved fact does not contradict to generated answer, so the intermediate answer is: Jill Biden\n",
      "\n",
      "Generated answer: iPhone 5 is produced by Apple.\n",
      "Retrieved fact: The company that produced iPhone 5 is Iveco.\n",
      "Retrieved fact contradicts to generated answer, so the intermediate answer is: Iveco\n",
      "\n",
      "Generated answer: Iveco was founded by Giovanni Agnelli.\n",
      "Retrieved fact: House of Bonaparte was founded by Gustav I of Sweden.\n",
      "Retrieved fact does not contradict to generated answer, so the intermediate answer is: Giovanni Agnelli\n",
      "\n",
      "Generated answer: Giovanni Agnelli is a citizen of Italy.\n",
      "Retrieved fact: Giovanni Agnelli is a citizen of Niger.\n",
      "Retrieved fact contradicts to generated answer, so the intermediate answer is: Niger.\n",
      "\n",
      "Generated answer: Niger is situated on Africa.\n",
      "Retrieved fact: Kingdom of England is located in the continent of North America.\n",
      "Retrieved fact does not contradict to generated answer, so the intermediate answer is: Africa.\n",
      "\n",
      "\n",
      "Generated answer:The head of state of Croatia is KolindaGrabar-Kitarović.\n",
      "Retrieved fact:The name of the current head of state in Austria is Kingdomof Italy.\n",
      "\n",
      "Retrieved fact contradicts to generated answer, so the intermediate answer is: Kolinda Grabar-Kitarović\n",
      "\n",
      "Generated answer: The head of state of Austria is President Alexander Van der Bellen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('prompts/test_contra_prompt.txt', 'r') as f:\n",
    "    task_prompt_contra = f.read()\n",
    "\n",
    "Generated_answer = \"Generated answer:The head of state of Croatia is KolindaGrabar-Kitarović.\\n\"\n",
    "Retrieved_fact = \"Retrieved fact:The name of the current head of state in Austria is Kingdomof Italy.\"\n",
    "prompt = task_prompt+'\\n\\n'+Generated_answer+Retrieved_fact\n",
    "start = len(prompt)\n",
    "print(prompt)\n",
    "gen = call_gpt(prompt, start)\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对retrieve_fact影响subquestion的生成，试试换个retrieve_fact或者不给retrieve_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 15.78 GiB total capacity; 14.83 GiB already allocated; 13.69 MiB free; 15.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 33\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39m#start = len(prompt_none)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m#gen_none = call_gpt(prompt_none, start)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m#start = len(prompt_object)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m#gen_object = call_gpt(prompt_object, start)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m start \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(prompt_relation)\n\u001b[0;32m---> 33\u001b[0m gen_relation \u001b[39m=\u001b[39m call_gpt(prompt_relation, start)\n\u001b[1;32m     35\u001b[0m start \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(prompt_other)\n\u001b[1;32m     36\u001b[0m gen_other \u001b[39m=\u001b[39m call_gpt(prompt_other, start)\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mcall_gpt\u001b[0;34m(cur_prompt, start)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_gpt\u001b[39m(cur_prompt, start):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# 将输入文本编码为模型输入\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     input_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(cur_prompt, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 4\u001b[0m     output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(input_ids, max_length\u001b[39m=\u001b[39;49minput_ids\u001b[39m.\u001b[39;49msize()[\u001b[39m1\u001b[39;49m]\u001b[39m+\u001b[39;49m\u001b[39m100\u001b[39;49m,num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m     generated_text \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(output[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     rest \u001b[39m=\u001b[39m generated_text[start:]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/generation/utils.py:1602\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1585\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massisted_decoding(\n\u001b[1;32m   1586\u001b[0m         input_ids,\n\u001b[1;32m   1587\u001b[0m         assistant_model\u001b[39m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1599\u001b[0m     )\n\u001b[1;32m   1600\u001b[0m \u001b[39mif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1601\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1602\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1603\u001b[0m         input_ids,\n\u001b[1;32m   1604\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1605\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1606\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1607\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1608\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1609\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1610\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1611\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1612\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1613\u001b[0m     )\n\u001b[1;32m   1615\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1616\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/generation/utils.py:2450\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2447\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2449\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2450\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2451\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2452\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2453\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2454\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2455\u001b[0m )\n\u001b[1;32m   2457\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2458\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:855\u001b[0m, in \u001b[0;36mGPTJForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    853\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m--> 855\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m    856\u001b[0m     input_ids,\n\u001b[1;32m    857\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    858\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    859\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m    860\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    861\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    862\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    863\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    864\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    865\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    866\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    867\u001b[0m )\n\u001b[1;32m    868\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    870\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:690\u001b[0m, in \u001b[0;36mGPTJModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    681\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    682\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    683\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m         head_mask[i],\n\u001b[1;32m    688\u001b[0m     )\n\u001b[1;32m    689\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[1;32m    691\u001b[0m         hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    692\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    693\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    694\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    695\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m    696\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    697\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    698\u001b[0m     )\n\u001b[1;32m    700\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    701\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:309\u001b[0m, in \u001b[0;36mGPTJBlock.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, position_ids, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    307\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    308\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 309\u001b[0m attn_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[1;32m    310\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    311\u001b[0m     layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    312\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    313\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    314\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    315\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    316\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    318\u001b[0m attn_output \u001b[39m=\u001b[39m attn_outputs[\u001b[39m0\u001b[39m]  \u001b[39m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m outputs \u001b[39m=\u001b[39m attn_outputs[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:237\u001b[0m, in \u001b[0;36mGPTJAttention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, position_ids, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    234\u001b[0m     q_rot \u001b[39m=\u001b[39m apply_rotary_pos_emb(q_rot, sin, cos)\n\u001b[1;32m    236\u001b[0m     key \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([k_rot, k_pass], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 237\u001b[0m     query \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([q_rot, q_pass], dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     key \u001b[39m=\u001b[39m apply_rotary_pos_emb(key, sin, cos)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 15.78 GiB total capacity; 14.83 GiB already allocated; 13.69 MiB free; 15.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "with open('prompts/MeLLo-prompt.txt', 'r') as f:\n",
    "    task_prompt = f.read()\n",
    "question = \"What is the capital of the country to which Lou Pearlmanbelonged?\\n\"\n",
    "gen_1 = \"\\nSubquestion: What is the name of the country to which LouPearlman belonged?\\nGenerated answer: The country to which Lou Pearlmanbelonged is United States of America.\\n\"\n",
    "retrieve_1 = \"Lou Pearlman is a citizen of India.\"\n",
    "gen_2 = \"\\nRetrieved fact contradicts to generated answer, so the intermediateanswer is: India\\nSubquestion: What is the capital of India?\\nGenerated answer:The capital of India is New Delhi.\\n\"\n",
    "retrieve_2_none = \".\"\n",
    "retrieve_2_subject = \"The capital of China is Bengaluru.\"\n",
    "retrieve_2_object = \"The capital of Spain is Beijing.\"\n",
    "retrieve_2_relation = \"The most popular city of Spain is Bengaluru.\"\n",
    "retrieve_2_other = \"The piggpy peggy is a pink pig.\"\n",
    "retrieve_2_real = \"The capital of India is Taloga.\"\n",
    "\n",
    "p = task_prompt+\"\\n\\n\"+question+gen_1+'Retrieved fact: '+retrieve_1+gen_2+'Retrieved fact: '\n",
    "#print(p)\n",
    "prompt_none = p + retrieve_2_none\n",
    "prompt_subject = p + retrieve_2_subject\n",
    "prompt_object = p + retrieve_2_object\n",
    "prompt_relation = p + retrieve_2_relation\n",
    "prompt_other = p + retrieve_2_other\n",
    "prompt_real = p + retrieve_2_real\n",
    "\n",
    "#start = len(prompt_none)\n",
    "#gen_none = call_gpt(prompt_none, start)\n",
    "\n",
    "#start = len(prompt_subject)\n",
    "#gen_subject = call_gpt(prompt_subject, start)\n",
    "\n",
    "#start = len(prompt_object)\n",
    "#gen_object = call_gpt(prompt_object, start)\n",
    "\n",
    "start = len(prompt_relation)\n",
    "gen_relation = call_gpt(prompt_relation, start)\n",
    "\n",
    "start = len(prompt_other)\n",
    "gen_other = call_gpt(prompt_other, start)\n",
    "\n",
    "start = len(prompt_real)\n",
    "gen_real = call_gpt(prompt_real, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Retrieved fact contradicts to generated answer, so the intermediate answer is: Taloga\n",
      "Subquestion: What is the name of the country to which Taloga belongs?\n",
      "Generated answer: The country to which Taloga belongs is India.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gen_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中文edit，英文CoT和prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:01<00:00, 49.43it/s]\n",
      " 50%|█████     | 1/2 [05:00<05:00, 300.26s/it]"
     ]
    }
   ],
   "source": [
    "with open ('new_facts_ch.txt','r',encoding='utf-8') as f:\n",
    "    new_fact_ch = f.readlines()\n",
    "new_facts_ch = []\n",
    "for fact in new_fact_ch:\n",
    "    fact = fact.strip('\\n')\n",
    "    new_facts_ch.append(fact)\n",
    "\n",
    "embs_ch = get_sent_embeddings(new_facts_ch, contriever, tokenizer_con)\n",
    "\n",
    "T = 10\n",
    "\n",
    "cor = 0\n",
    "tot = 0\n",
    "start = len(task_prompt)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "record_list_ch = []\n",
    "for d in tqdm(dataset[:2]):\n",
    "    #print(d)\n",
    "    real_edit = []\n",
    "    tot += 1\n",
    "    hop = len(d[\"new_single_hops\"])\n",
    "    #print(hop)\n",
    "    #用于记录该问题应该retrieve哪些edit fact\n",
    "    for r in d[\"requested_rewrite\"]:\n",
    "        real_edit.append(f'{r[\"prompt\"].format(r[\"subject\"])} {r[\"target_new\"][\"str\"]}')\n",
    "    \n",
    "    cnt = 0\n",
    "    for q in d[\"questions\"]:\n",
    "        cnt+=1\n",
    "        retrieved_facts = []\n",
    "        found_ans = False\n",
    "        prompt = task_prompt + \"\\n\\nQustion: \" + q\n",
    "        flag = 0\n",
    "        \n",
    "        for i in range(4):\n",
    "            # prompt the model to generate a subquestion and a tentative answer\n",
    "            start = len(prompt)\n",
    "            gen = call_gpt(prompt, start)\n",
    "            last_sent = gen.strip().split('\\n')[-1]\n",
    "            \n",
    "            # if final answer is there, get the answer and exit\n",
    "            if last_sent.startswith('Final answer: '):\n",
    "                found_ans = True\n",
    "                ans = last_sent[len(\"Final answer: \"):]\n",
    "                break\n",
    "            \n",
    "            # otherwise, extract the generated subquestion\n",
    "            if len(gen.strip().split('\\n')) < 2:\n",
    "                record = {'id':tot,'hop':hop,'question':q,'real_edit':real_edit,'retrieve_facts':retrieved_facts,'answer':\"failed_1\"}\n",
    "                record_list_ch.append(record)\n",
    "                flag = 1\n",
    "                break # failed case\n",
    "            subquestion = gen.strip().split('\\n')[-2]\n",
    "            if not subquestion.startswith('Subquestion: '):\n",
    "                record = {'id':tot,'hop':hop,'question':q,'real_edit':real_edit,'retrieve_facts':retrieved_facts,'answer':\"failed_2\"}\n",
    "                record_list_ch.append(record)\n",
    "                flag = 1\n",
    "                break # failed case\n",
    "            subquestion = subquestion[len(\"Subquestion: \"):]\n",
    "            \n",
    "            # retrieve an edited fact using the generated subquestion\n",
    "            fact_ids = retrieve_facts(subquestion, embs_ch, contriever, tokenizer_con)\n",
    "            fact_sent = new_facts_ch[fact_ids[0]]\n",
    "            retrieved_facts.append(fact_sent)\n",
    "            \n",
    "            # put the retrieved fact at the end of the prompt, the model self-checks if it contradicts\n",
    "            prompt = prompt + gen + 'Retrieved fact: ' + fact_sent + '.'\n",
    "            \n",
    "        prompt = prompt + gen\n",
    "        \n",
    "        if not found_ans:\n",
    "            if flag == 0:\n",
    "                record = {'id':tot,'hop':hop,'question':q,'real_edit':real_edit,'retrieve_facts':retrieved_facts,'answer':\"no_final_ans\"}\n",
    "                record_list_ch.append(record)\n",
    "            continue\n",
    "        # if the answer is correct\n",
    "        if ans == d[\"new_answer\"] or ans in d[\"new_answer_alias\"]:\n",
    "            cor += 1\n",
    "            break\n",
    "        else:\n",
    "            record = {'id':tot,'hop':hop,'question':q,'real_edit':real_edit,'retrieve_facts':retrieved_facts,'answer':\"not_correct_ans\"}\n",
    "            record_list_ch.append(record)\n",
    "            \n",
    "print(f'Multi-hop acc = {cor / tot} ({cor} / {tot})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'record_list_ch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/MQuAKE/test.ipynb 单元格 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bregion-45.autodl.pro/root/MQuAKE/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m record_list_ch\n",
      "\u001b[0;31mNameError\u001b[0m: name 'record_list_ch' is not defined"
     ]
    }
   ],
   "source": [
    "record_list_ch\n",
    "with open(\"record_list_ch.json\", \"w\") as f:\n",
    "    json.dump(record_list_ch, f,ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
