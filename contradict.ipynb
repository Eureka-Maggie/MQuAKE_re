{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianxueyun/anaconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 33/33 [00:14<00:00,  2.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:3\"\n",
    "model_dir = '/home/tianxueyun/llama-7b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir,torch_dtype=torch.float16).to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(token_embeddings, mask):\n",
    "    token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "    sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "    return sentence_embeddings\n",
    "\n",
    "def get_sent_embeddings(sents, contriever, tok, BSZ=32):    \n",
    "    all_embs = []\n",
    "    for i in tqdm(range(0, len(sents), BSZ)):\n",
    "        sent_batch = sents[i:i+BSZ]\n",
    "        inputs = tok(sent_batch, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = contriever(**inputs)\n",
    "            embeddings = mean_pooling(outputs[0], inputs['attention_mask'])\n",
    "        all_embs.append(embeddings)\n",
    "    all_embs = torch.vstack(all_embs)\n",
    "    return all_embs\n",
    "\n",
    "def retrieve_facts(query, fact_embs, contriever, tok, k=1):\n",
    "    inputs = tok([query], padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = contriever(**inputs)\n",
    "        query_emb = mean_pooling(outputs[0], inputs['attention_mask'])\n",
    "    sim = (query_emb @ fact_embs.T)[0]\n",
    "    knn = sim.topk(k, largest=True)\n",
    "    return knn.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取retrieved fact的embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:02<00:00, 34.91it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('/home/tianxueyun/MQuAKE/datasets/MQuAKE-CF-3k.json', 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "new_facts = set()\n",
    "for d in dataset:\n",
    "    for r in d[\"requested_rewrite\"]:\n",
    "        new_facts.add(f'{r[\"prompt\"].format(r[\"subject\"])} {r[\"target_new\"][\"str\"]}')\n",
    "new_facts = list(new_facts)\n",
    "\n",
    "contriever = AutoModel.from_pretrained(\"/home/tianxueyun/MQuAKE/contriever\").to(device)\n",
    "tokenizer_con = AutoTokenizer.from_pretrained(\"/home/tianxueyun/MQuAKE/contriever\")\n",
    "embs = get_sent_embeddings(new_facts, contriever, tokenizer_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建用于判断contradict的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [01:06<00:00, 45.40it/s] \n",
      "100%|██████████| 3000/3000 [00:30<00:00, 97.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2785\n",
      "1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cf_dataset = []\n",
    "test = set()\n",
    "contradict_count = 0\n",
    "not_contradict_count = 0\n",
    "for d in tqdm(dataset):\n",
    "    for qs in d['requested_rewrite']:\n",
    "        record = []\n",
    "        question = qs['question']\n",
    "        len_old = len(test)\n",
    "        test.add(question)\n",
    "        if (len(test)>len_old) :\n",
    "            gold_retrieve_fact = f'{qs[\"prompt\"].format(qs[\"subject\"])} {qs[\"target_new\"][\"str\"]}'\n",
    "            fact_ids = retrieve_facts(question, embs, contriever, tokenizer_con)\n",
    "            retrieved_fact = new_facts[fact_ids[0]]\n",
    "            ans_correct = qs[\"target_new\"][\"str\"]\n",
    "            gold_generate = f'{qs[\"prompt\"].format(qs[\"subject\"])} {qs[\"target_true\"][\"str\"]}'\n",
    "            #print('gold_retrieve_fact:',gold_retrieve_fact)\n",
    "            #print('gold_generate:',gold_generate)\n",
    "            \n",
    "            #找ans_alias\n",
    "            for hop in d['new_single_hops']:\n",
    "                if question == hop['question']:\n",
    "                    ans_alias = hop['answer_alias']\n",
    "            #print(ans_alias)\n",
    "\n",
    "            record.append({'question':question,'gold_retrieve_fact':gold_retrieve_fact,\n",
    "                        'retrieved_fact':retrieved_fact,'gold_generate':gold_generate,'answer_correct':ans_correct,\n",
    "                        'ans_alias':ans_alias,'contradict':'contradict'})\n",
    "            cf_dataset.append(record)\n",
    "            contradict_count+=1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "for d in tqdm(dataset):\n",
    "    for qs in d['single_hops']:\n",
    "        record = []\n",
    "        question = qs['question']\n",
    "        contradict_len = len(test)\n",
    "        test.add(question)\n",
    "        if (len(test)>contradict_len):\n",
    "            gold_retrieve_fact = qs['cloze']+\" \"+qs['answer']\n",
    "            #gold_retrieve_fact = \"\"\n",
    "            fact_ids = retrieve_facts(question, embs, contriever, tokenizer_con)\n",
    "            retrieved_fact = new_facts[fact_ids[0]]\n",
    "            ans_correct = qs['answer']\n",
    "            ans_alias = qs['answer_alias']\n",
    "            #print(ans_alias)\n",
    "            gold_generate = qs['cloze']+\" \"+qs['answer']\n",
    "            record.append({'question':question,'gold_retrieve_fact':gold_retrieve_fact,\n",
    "                        'retrieved_fact':retrieved_fact,'gold_generate':gold_generate,'answer_correct':ans_correct,\n",
    "                        'ans_alias':ans_alias,'contradict':'not contradict'})\n",
    "            cf_dataset.append(record)\n",
    "            not_contradict_count+=1\n",
    "        else:\n",
    "            continue\n",
    "print(contradict_count)\n",
    "print(not_contradict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'question': 'What position does Erik Spoelstra play?',\n",
       "   'gold_retrieve_fact': 'Erik Spoelstra plays the position of point guard',\n",
       "   'retrieved_fact': 'Rik Smits plays the position of punter',\n",
       "   'gold_generate': 'Erik Spoelstra plays the position of point guard',\n",
       "   'answer_correct': 'point guard',\n",
       "   'ans_alias': [],\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Which company is Windows Phone 8 produced by?',\n",
       "   'gold_retrieve_fact': 'The company that produced Windows Phone 8 is Microsoft',\n",
       "   'retrieved_fact': 'The company that produced Windows Phone 8.1 is Toyota',\n",
       "   'gold_generate': 'The company that produced Windows Phone 8 is Microsoft',\n",
       "   'answer_correct': 'Microsoft',\n",
       "   'ans_alias': ['MS',\n",
       "    'Micro-Soft',\n",
       "    'Microsoft Corp.',\n",
       "    'Microsoft Corporation',\n",
       "    'MSFT',\n",
       "    'MICROSOFT TECHNOLOGY LICENSING, LLC     (Redmond, WA)'],\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Who performed Illmatic?',\n",
       "   'gold_retrieve_fact': 'Illmatic was performed by Nas',\n",
       "   'retrieved_fact': 'Chris Claremont is famous for Arthashastra',\n",
       "   'gold_generate': 'Illmatic was performed by Nas',\n",
       "   'answer_correct': 'Nas',\n",
       "   'ans_alias': ['Nas Escobar',\n",
       "    'Nasir bin Olu Dara Jones',\n",
       "    'Nasir Jones',\n",
       "    'Nasty Nas'],\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Who is Nas married to?',\n",
       "   'gold_retrieve_fact': 'Nas is married to Kelis',\n",
       "   'retrieved_fact': 'Ibrahim Nasir is affiliated with the religion of Catholic Church',\n",
       "   'gold_generate': 'Nas is married to Kelis',\n",
       "   'answer_correct': 'Kelis',\n",
       "   'ans_alias': ['Kelis Rogers', 'Kelis Rogers Caloteira'],\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Which sport is Mitsuyo Maeda associated with?',\n",
       "   'gold_retrieve_fact': 'Mitsuyo Maeda is associated with the sport of judo',\n",
       "   'retrieved_fact': 'quarterback is associated with the sport of sumo',\n",
       "   'gold_generate': 'Mitsuyo Maeda is associated with the sport of judo',\n",
       "   'answer_correct': 'judo',\n",
       "   'ans_alias': [],\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'What position does Asi Taulava play?',\n",
       "   'gold_retrieve_fact': 'Asi Taulava plays the position of center',\n",
       "   'retrieved_fact': 'Diana Taurasi is associated with the sport of rugby union',\n",
       "   'gold_generate': 'Asi Taulava plays the position of center',\n",
       "   'answer_correct': 'center',\n",
       "   'ans_alias': ['pivot',\n",
       "    'basketball center',\n",
       "    'basketball pivot',\n",
       "    'center (basketball)'],\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Who is the original broadcaster of Larry King Live?',\n",
       "   'gold_retrieve_fact': 'The origianl broadcaster of Larry King Live is CNN',\n",
       "   'retrieved_fact': 'The origianl broadcaster of The Larry Sanders Show is Doordarshan',\n",
       "   'gold_generate': 'The origianl broadcaster of Larry King Live is CNN',\n",
       "   'answer_correct': 'CNN',\n",
       "   'ans_alias': ['Cable News Network', 'CNN News', 'CNN USA', 'CNN/U.S.'],\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Which company is Ford Torino produced by?',\n",
       "   'gold_retrieve_fact': 'The company that produced Ford Torino is Ford Motor Company',\n",
       "   'retrieved_fact': 'The company that produced Ford Mustang is Fiat S.p.A.',\n",
       "   'gold_generate': 'The company that produced Ford Torino is Ford Motor Company',\n",
       "   'answer_correct': 'Ford Motor Company',\n",
       "   'ans_alias': ['Ford',\n",
       "    'Ford Motors',\n",
       "    'FoMoCo',\n",
       "    'Ford Motor',\n",
       "    'Ford Motor Co.',\n",
       "    'Ford Motor Corporation'],\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Who is the developer of iPad Pro?',\n",
       "   'gold_retrieve_fact': 'iPad Pro was developed by Apple Inc.',\n",
       "   'retrieved_fact': 'iPad (3rd generation) was developed by ARM Holdings',\n",
       "   'gold_generate': 'iPad Pro was developed by Apple Inc.',\n",
       "   'answer_correct': 'Apple Inc.',\n",
       "   'ans_alias': ['Apple Inc.     (Cupertino, CA)',\n",
       "    'AAPL',\n",
       "    'Apple Computer Inc',\n",
       "    'Apple Computer Inc.',\n",
       "    'Apple Computer Incorporated',\n",
       "    'Apple Computer, Inc.',\n",
       "    'Apple Inc.',\n",
       "    'Apple Incorporated',\n",
       "    'Apple, Inc'],\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Which university was Andrew Bogut educated at?',\n",
       "   'gold_retrieve_fact': 'The univeristy where Andrew Bogut was educated is University of Utah',\n",
       "   'retrieved_fact': 'Muggsy Bogues plays the position of left fielder',\n",
       "   'gold_generate': 'The univeristy where Andrew Bogut was educated is University of Utah',\n",
       "   'answer_correct': 'University of Utah',\n",
       "   'ans_alias': ['The U',\n",
       "    'UU',\n",
       "    'Deseret University',\n",
       "    'The University of Utah',\n",
       "    'U. of U.',\n",
       "    'University of Deseret',\n",
       "    'University of the State of Deseret',\n",
       "    'Utah University'],\n",
       "   'contradict': 'not contradict'}]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_dataset[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看有多少real fact和retrieved fact不一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2718\n",
      "4062\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in cf_dataset:\n",
    "    if i[0]['gold_retrieve_fact']==i[0]['retrieved_fact']:\n",
    "        count+=1\n",
    "print(count)\n",
    "print(len(cf_dataset))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存cf_dataset到json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.dumps(cf_dataset)\n",
    "with open('contradict.json', 'w') as file:\n",
    "    file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4062"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('contradict.json', 'r') as file:\n",
    "    j = json.load(file)\n",
    "len(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试判断contradict/ans/contradict+ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/tianxueyun/MQuAKE/prompts/contradict-prompt.txt', 'r') as f:\n",
    "    contradict_prompt = f.read()\n",
    "\n",
    "with open('/home/tianxueyun/MQuAKE/prompts/contradict-ans-prompt.txt', 'r') as f:\n",
    "    contradict_ans_prompt = f.read()\n",
    "\n",
    "with open('/home/tianxueyun/MQuAKE/prompts/ans-prompt.txt', 'r') as f:\n",
    "    ans_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(prompt):\n",
    "    start = len(prompt)\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length = input_ids.size()[1]+80,num_return_sequences=1) #max_new_tokens=80\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    #print(generated_text)\n",
    "    rest = generated_text[start:]\n",
    "    fa_index = rest.find('\\n\\nQuestion:') #找final_ans\n",
    "    rf_index = rest.find('Retrieved fact:')\n",
    "    if (fa_index > rf_index and rf_index!=-1 ) or fa_index == -1:\n",
    "        index = rf_index\n",
    "    else:\n",
    "        index = fa_index\n",
    "\n",
    "    generate_q_a = rest[:index]\n",
    "    #print(generate_q_a)\n",
    "    return generate_q_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianxueyun/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      " 10%|█         | 2/20 [1:09:46<12:11:01, 2436.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,   894, 29901, 11644,   338,   306, 29894, 18330, 27504, 29915,\n",
      "         29879,   805,  1709, 29973,    13, 24565,  1234, 29901,   306, 29894,\n",
      "         18330, 27504, 29915, 29879,   805,  1709,   338,   435,  1965,   476,\n",
      "          1878,  1089, 29889,    13,  8015,  2546,  1490,  2114, 29901,   306,\n",
      "         29894, 18330,   350,  3615,   338,  8300,   304,  3685,  9716, 29874,\n",
      "         20939,   265, 29889,    13,  8015,  2546,  1490,  2114,   947,   451,\n",
      "         27877,   304,  5759,  1234, 29889,   450,  1234,   338, 29901,   435,\n",
      "          1965,   476,  1878,  1089, 29889,    13,    13, 16492, 29901,  1724,\n",
      "           338,   278,  4234,   310, 18363,  4034,   310,   435,  1965,   476,\n",
      "          1878,  1089, 29973,    13, 24565,  1234, 29901,   450,  4234,   310,\n",
      "         18363,  4034,   310,   435,  1965,   476,  1878,  1089,   338,  3303,\n",
      "          3900, 29889,    13,  8015,  2546,  1490,  2114, 29901,   435,  1965,\n",
      "           476,  1878,  1089,   338,   263, 14497,   264,   310,  7400, 29889,\n",
      "            13,  8015,  2546,  1490,  2114, 27877, 29879,   304,  5759,  1234,\n",
      "         29889,   450,  1234,   338, 29901,  7400, 29889,    13,    13, 16492,\n",
      "         29901,  1724,   338,   278,  7483,  4272,   310,  7400, 29973,    13,\n",
      "         24565,  1234, 29901, 29871,   450,  7483,  4272,   310,  7400,   338,\n",
      "         13476, 10011, 29889,    13,  8015,  2546,  1490,  2114, 29901,   450,\n",
      "          7483,  4272,   310,  3303,  3900,   310,  6813,   338, 27689, 29889,\n",
      "            13,  8015,  2546,  1490,  2114,   947,   451, 27877,   304,  5759,\n",
      "          1234, 29889,   450,  1234,   338, 29901, 13476, 10011, 29889,    13,\n",
      "            13, 16492, 29901,  1724,   338,   278,  4234,   310, 18363,  4034,\n",
      "           310, 21431, 29876, 13015, 29973,    13, 24565,  1234, 29901, 21431,\n",
      "         29876, 13015,   338,   263, 14497,   264,   310,  3303,  3900,   310,\n",
      "          6813, 29889,    13,  8015,  2546,  1490,  2114, 29901, 21431, 29876,\n",
      "         13015,   338,   263, 14497,   264,   310,  8764, 28752, 29889,    13,\n",
      "          8015,  2546,  1490,  2114, 27877, 29879,   304,  5759,  1234, 29889,\n",
      "           450,  1234,   338, 29901,  8764, 28752, 29889,    13,    13, 16492,\n",
      "         29901, 11644,   338,   278,   805,  1709,   310, 11131,   350,  3615,\n",
      "         29973,    13, 24565,  1234, 29901,   450,   805,  1709,   310, 11131,\n",
      "           350,  3615,   338,   435,   453,   350,  3615, 29889,    13,  8015,\n",
      "          2546,  1490,  2114, 29901,   450,   805,  1709,   310, 11131,  6682,\n",
      "           338,   382,  3703, 24518, 29889,    13,  8015,  2546,  1490,  2114,\n",
      "           947,   451, 27877,   304,  5759,  1234, 29889,   450,  1234,   338,\n",
      "         29901,   435,   453,   350,  3615, 29889,    13,    13, 16492, 29901,\n",
      "         11644,   338,   278,  2343,   310,  2106,   297,  3303,  3900,   310,\n",
      "          6813, 29973,    13, 24565,  1234, 29901,   450,  3148,  6673,   338,\n",
      "         18935, 27504, 29889,    13,  8015,  2546,  1490,  2114, 29901,   450,\n",
      "          2343,   310,  2106,   297,  3303,  3900,   310,  6813,   338, 11131,\n",
      "           350,  3615, 29889,    13,  8015,  2546,  1490,  2114, 27877, 29879,\n",
      "           304,  5759,  1234, 29889,   450,  1234,   338, 29901, 11131,   350,\n",
      "          3615, 29889,    13,    13, 16492, 29901, 11644,   338,   278, 25331,\n",
      "           310,   306,   345,  1111, 29973,    13, 24565,  1234, 29901,   306,\n",
      "           345,  1111,   471, 11091,   491, 12874,  4059, 29876,  5481, 29889,\n",
      "            13,  8015,  2546,  1490,  2114, 29901,  5619,   310,  8396,   481,\n",
      "         11908,   471, 11091,   491, 18305,   306,   310, 24506, 29889,    13,\n",
      "          8015,  2546,  1490,  2114,   947,   451, 27877,   304,  5759,  1234,\n",
      "         29889,   450,  1234,   338, 29901, 12874,  4059, 29876,  5481, 29889,\n",
      "            13,    13, 16492, 29901,  8449,  5001,   338, 18483, 29871, 29945,\n",
      "          7371,   491, 29973,    13, 24565,  1234, 29901, 18483, 29871, 29945,\n",
      "           338,  7371,   491, 12113, 29889,    13,  8015,  2546,  1490,  2114,\n",
      "         29901,   450,  5001,   393,  7371, 18483, 29871, 29945,   338,   306,\n",
      "           345,  1111, 29889,    13,  8015,  2546,  1490,  2114, 27877, 29879,\n",
      "           304,  5759,  1234, 29889,   450,  1234,   338, 29901,   306,   345,\n",
      "          1111, 29889,    13,    13, 16492, 29901,  1551,   607, 25523,   338,\n",
      "         20537, 24046, 29973,    13, 24565,  1234, 29901, 20537,   338, 24046,\n",
      "           373, 10557, 29889,    13,  8015,  2546,  1490,  2114, 29901, 12626,\n",
      "           310,  5408,   338,  5982,   297,   278, 25523,   310,  4644,  6813,\n",
      "         29889,    13,  8015,  2546,  1490,  2114,   947,   451, 27877,   304,\n",
      "          5759,  1234, 29889,   450,  1234,   338, 29901, 10557, 29889,    13,\n",
      "            13, 16492, 29901,  1724,   338,   278,  4234,   310, 18363,  4034,\n",
      "           310, 12874,  4059, 29876,  5481, 29973,    13, 24565,  1234, 29901,\n",
      "         12874,  4059, 29876,  5481,   338,   263, 14497,   264,   310, 12730,\n",
      "         29889,    13,  8015,  2546,  1490,  2114, 29901, 12874,  4059, 29876,\n",
      "          5481,   338,   263, 14497,   264,   310, 20537, 29889,    13,  8015,\n",
      "          2546,  1490,  2114, 27877, 29879,   304,  5759,  1234, 29889,   450,\n",
      "          1234,   338, 29901, 20537, 29889,    13,    13, 16492, 29901,  1724,\n",
      "           338,   382, 29875,   436,  3350,   438,  1388, 13834,   363, 29973,\n",
      "            13, 24565,  1234, 29901,   382, 29875,   436,  3350,   438,  1388,\n",
      "           338, 13834,   363,  3118, 26005,   346, 29889,    13,  8015,  2546,\n",
      "          1490,  2114, 29901,   382, 29875,   436,  3350,   438,  1388,   338,\n",
      "         13834,   363,   383,  1310,   349,  2335, 29889,    13,  8015,  2546,\n",
      "          1490,  2114,   947,   451, 27877,   304,  5759,  1234, 29889,   450,\n",
      "          1234,   338, 29901,  3118, 26005,   346, 29889]], device='cuda:3')\n"
     ]
    }
   ],
   "source": [
    "#读取contradict数据集\n",
    "with open('contradict.json', 'r') as file:\n",
    "    j = json.load(file)\n",
    "cor_c = 0 \n",
    "cor_n = 0 \n",
    "tot = 0\n",
    "err = []\n",
    "for data in tqdm(j[2700:2720]):\n",
    "    tot+=1\n",
    "    #print(data)\n",
    "    question = data[0]['question']\n",
    "    gold_retrieve_fact = data[0]['gold_retrieve_fact']\n",
    "    retrieved_fact = data[0]['retrieved_fact']\n",
    "    gold_generate = data[0]['gold_generate']\n",
    "    answer_correct = data[0]['answer_correct']\n",
    "    contradict = data[0]['contradict']\n",
    "    ans_alias = data[0]['ans_alias']\n",
    "    prompt = contradict_ans_prompt +'\\n\\nQuestion: '+ question + '\\nGenerated answer: ' + gold_generate +'.\\n'+ 'Retrieved fact: ' + gold_retrieve_fact + '.'\n",
    "    #print(prompt)\n",
    "    #gen = get_ans(prompt)\n",
    "    #last_sent = gen.strip().split('\\n')[-1]\n",
    "    #print('last sent:',last_sent)\n",
    "\n",
    "    #if last_sent.startswith('Generated answer:'):\n",
    "    #    prompt = prompt + gen + 'Retrieved fact: ' + gold_retrieve_fact + '.' \n",
    "    #else:\n",
    "    #    print(last_sent)\n",
    "    #    continue\n",
    "    \n",
    "    gen = get_ans(prompt)\n",
    "    last_sent = gen.strip().split('\\n')[-1]\n",
    "    if last_sent.startswith('Retrieved fact'):\n",
    "        pos = last_sent.find('. The answer is: ')\n",
    "        length = len('. The answer is: ')\n",
    "        if len(last_sent[15:pos-21])==10: #判断为contradict\n",
    "            if contradict == 'contradict' :\n",
    "                ans = last_sent[pos+length:-1]\n",
    "                if ans == answer_correct or ans in ans_alias:\n",
    "                    cor_c+=1\n",
    "            else:\n",
    "                err.append(data)\n",
    "                #print(data)\n",
    "                print('c:',last_sent)\n",
    "        else: #判断为not contradict\n",
    "            if contradict == 'not contradict':\n",
    "                ans = last_sent[pos+length:-1]\n",
    "                if ans == answer_correct or ans in ans_alias:\n",
    "                    cor_n+=1\n",
    "                else:\n",
    "                    print(ans)\n",
    "                    print(last_sent)\n",
    "                #print(ans)\n",
    "            else:\n",
    "                ans = last_sent[pos+length:-1]\n",
    "                err.append(data)\n",
    "    else:\n",
    "        print('not_in:',gen)\n",
    "print('total:',(cor_c+cor_n)/tot)\n",
    "print('cor_c:',cor_c)\n",
    "print('cor_n:',cor_n)\n",
    "\n",
    "json_data = json.dumps(err)\n",
    "with open('err_contradict_ans.json', 'w') as file:\n",
    "    file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'question': 'What position does Erik Spoelstra play?',\n",
       "   'gold_retrieve_fact': 'Erik Spoelstra plays the position of point guard',\n",
       "   'retrieved_fact': 'Rik Smits plays the position of punter',\n",
       "   'gold_generate': 'Erik Spoelstra plays the position of point guard',\n",
       "   'answer_correct': 'point guard',\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Which company is Windows Phone 8 produced by?',\n",
       "   'gold_retrieve_fact': 'The company that produced Windows Phone 8 is Microsoft',\n",
       "   'retrieved_fact': 'The company that produced Windows Phone 8.1 is Toyota',\n",
       "   'gold_generate': 'The company that produced Windows Phone 8 is Microsoft',\n",
       "   'answer_correct': 'Microsoft',\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Who performed Illmatic?',\n",
       "   'gold_retrieve_fact': 'Illmatic was performed by Nas',\n",
       "   'retrieved_fact': 'Chris Claremont is famous for Arthashastra',\n",
       "   'gold_generate': 'Illmatic was performed by Nas',\n",
       "   'answer_correct': 'Nas',\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Who is Nas married to?',\n",
       "   'gold_retrieve_fact': 'Nas is married to Kelis',\n",
       "   'retrieved_fact': 'Ibrahim Nasir is affiliated with the religion of Catholic Church',\n",
       "   'gold_generate': 'Nas is married to Kelis',\n",
       "   'answer_correct': 'Kelis',\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Which sport is Mitsuyo Maeda associated with?',\n",
       "   'gold_retrieve_fact': 'Mitsuyo Maeda is associated with the sport of judo',\n",
       "   'retrieved_fact': 'quarterback is associated with the sport of sumo',\n",
       "   'gold_generate': 'Mitsuyo Maeda is associated with the sport of judo',\n",
       "   'answer_correct': 'judo',\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'What position does Asi Taulava play?',\n",
       "   'gold_retrieve_fact': 'Asi Taulava plays the position of center',\n",
       "   'retrieved_fact': 'Diana Taurasi is associated with the sport of rugby union',\n",
       "   'gold_generate': 'Asi Taulava plays the position of center',\n",
       "   'answer_correct': 'center',\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Who is the original broadcaster of Larry King Live?',\n",
       "   'gold_retrieve_fact': 'The origianl broadcaster of Larry King Live is CNN',\n",
       "   'retrieved_fact': 'The origianl broadcaster of The Larry Sanders Show is Doordarshan',\n",
       "   'gold_generate': 'The origianl broadcaster of Larry King Live is CNN',\n",
       "   'answer_correct': 'CNN',\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Which company is Ford Torino produced by?',\n",
       "   'gold_retrieve_fact': 'The company that produced Ford Torino is Ford Motor Company',\n",
       "   'retrieved_fact': 'The company that produced Ford Mustang is Fiat S.p.A.',\n",
       "   'gold_generate': 'The company that produced Ford Torino is Ford Motor Company',\n",
       "   'answer_correct': 'Ford Motor Company',\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Who is the developer of iPad Pro?',\n",
       "   'gold_retrieve_fact': 'iPad Pro was developed by Apple Inc.',\n",
       "   'retrieved_fact': 'iPad (3rd generation) was developed by ARM Holdings',\n",
       "   'gold_generate': 'iPad Pro was developed by Apple Inc.',\n",
       "   'answer_correct': 'Apple Inc.',\n",
       "   'contradict': 'not contradict'}],\n",
       " [{'question': 'Which university was Andrew Bogut educated at?',\n",
       "   'gold_retrieve_fact': 'The univeristy where Andrew Bogut was educated is University of Utah',\n",
       "   'retrieved_fact': 'Muggsy Bogues plays the position of left fielder',\n",
       "   'gold_generate': 'The univeristy where Andrew Bogut was educated is University of Utah',\n",
       "   'answer_correct': 'University of Utah',\n",
       "   'contradict': 'not contradict'}]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does not contradict\n",
      "Crotia\n"
     ]
    }
   ],
   "source": [
    "a = 'Retrieved fact does not contradicts to generated answer. The answer is: Crotia.'\n",
    "len('Retrieved fact')\n",
    "len('to generated answer.')\n",
    "#last_sent[15:-22] #len =10\n",
    "len(a[15:-22]) #len=19\n",
    "\n",
    "length = len('. The answer is: ')\n",
    "pos = a.find('. The answer is: ')\n",
    "contradict = a[15:pos-21]\n",
    "ans = a[pos+length:-1]\n",
    "print(contradict)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('../err_contradict_ans_llama13.json','r')as f:\n",
    "    lines = json.load(f)\n",
    "len(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
